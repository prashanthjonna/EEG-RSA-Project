{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa071c29",
   "metadata": {},
   "source": [
    "## Aim of this script : To run classification ML models on the EEG data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865bd1c4",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb8f847",
   "metadata": {},
   "source": [
    "Importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab12a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statistics import mean\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7751670c",
   "metadata": {},
   "source": [
    "Import \"Final_df.xlsx\" as a dataframe and create X (features) and y (results) lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f888323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_df = pd.read_excel(\"Final_df.xlsx\")\n",
    "\n",
    "X = Final_df.iloc[:,1:-1].values\n",
    "y = Final_df.iloc[:, -1].values\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)\n",
    "\n",
    "Participants_count = len(Final_df.index)//2\n",
    "\n",
    "LR_scores = []\n",
    "XGB_scores = []\n",
    "KNN_scores = []\n",
    "SVM_scores = []\n",
    "KSVM_scores = []\n",
    "NB_scores = []\n",
    "DTC_scores = []\n",
    "RFC_scores = []\n",
    "Model_scores_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82f9b6",
   "metadata": {},
   "source": [
    "For Leave one out cross validation (LOOCV method), drop out the pre and post info related to one participant, train the model using the remaining data. Test the model using the info which was dropped during the training stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5ac086",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Participants_count):\n",
    "\n",
    "    X_train = X.drop(labels = [i, i + Participants_count], axis=0)\n",
    "    y_train = y.drop(labels = [i, i + Participants_count], axis=0)\n",
    "    X_test = X.iloc[[i, i + Participants_count],:] \n",
    "    y_test = y.iloc[[i, i + Participants_count],:] \n",
    "\n",
    "    if(i==0):\n",
    "        X_train.to_excel(\"X_dataframe.xlsx\")\n",
    "        y_train.to_excel(\"y_dataframe.xlsx\")\n",
    "\n",
    "    # Feature Scaling\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "\n",
    "    # PCA - Principle Component Analysis\n",
    "\n",
    "    #pca = PCA(n_components = 0.95)\n",
    "    #X_train = pca.fit_transform(X_train)\n",
    "    #X_test = pca.transform(X_test)\n",
    "    #explained_variance = pca.explained_variance_ratio_\n",
    "    #print(explained_variance)\n",
    "\n",
    "    # LDA - Linear Discriminant Analysis\n",
    "\n",
    "    #lda = LDA(n_components = 1)\n",
    "    #X_train = lda.fit_transform(X_train,y_train)\n",
    "    #X_test = lda.transform(X_test)\n",
    "\n",
    "    # ML Models Accuracy Computation\n",
    "\n",
    "    LR_classifier = LogisticRegression(random_state = 0)\n",
    "    LR_classifier.fit(X_train, y_train)\n",
    "    LR_scores.append(LR_classifier.score(X_test,y_test))\n",
    "\n",
    "    XGB_classifier = XGBClassifier()\n",
    "    XGB_classifier.fit(X_train, y_train)\n",
    "    XGB_scores.append(XGB_classifier.score(X_test,y_test))\n",
    "    #plt.bar(range(len(XGB_classifier.feature_importances_)), XGB_classifier.feature_importances_)\n",
    "    #plt.show()\n",
    "\n",
    "    KNN_classifier = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2)\n",
    "    KNN_classifier.fit(X_train, y_train)\n",
    "    KNN_scores.append(KNN_classifier.score(X_test,y_test))\n",
    "\n",
    "    SVM_classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "    SVM_classifier.fit(X_train, y_train)\n",
    "    SVM_scores.append(SVM_classifier.score(X_test,y_test))\n",
    "\n",
    "    KSVM_classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "    KSVM_classifier.fit(X_train, y_train)\n",
    "    KSVM_scores.append(KSVM_classifier.score(X_test,y_test))\n",
    "\n",
    "    NB_classifier = GaussianNB()\n",
    "    NB_classifier.fit(X_train, y_train)\n",
    "    NB_scores.append(NB_classifier.score(X_test,y_test))\n",
    "\n",
    "    DTC_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    DTC_classifier.fit(X_train, y_train)\n",
    "    DTC_scores.append(DTC_classifier.score(X_test,y_test))\n",
    "\n",
    "    RFC_classifier = RandomForestClassifier(random_state=0)\n",
    "    RFC_classifier.fit(X_train, y_train)\n",
    "    RFC_scores.append(RFC_classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91872afe",
   "metadata": {},
   "source": [
    "We print out the mean of the accuracies obtained through each of the ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3305c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score : 0.5833333333333334\n",
      "XG Boost Score : 0.8333333333333334\n",
      "KNN Score : 0.5833333333333334\n",
      "SVM Score : 0.5833333333333334\n",
      "Kernel SVM Score : 0.5833333333333334\n",
      "Naive Bayes Score : 0.6666666666666666\n",
      "Decision Trees Classifier Score : 0.5\n",
      "Random Forest Classifier Score : 0.5\n"
     ]
    }
   ],
   "source": [
    "model_str = [\"Logistic Regression\",\"XG Boost\", \"KNN\", \"SVM\", \"Kernel SVM\", \"Naive Bayes\", \"Decision Trees Classifier\", \"Random Forest Classifier\"]\n",
    "\n",
    "Model_scores_list.append(LR_scores)\n",
    "Model_scores_list.append(XGB_scores)\n",
    "Model_scores_list.append(KNN_scores)\n",
    "Model_scores_list.append(SVM_scores)\n",
    "Model_scores_list.append(KSVM_scores)\n",
    "Model_scores_list.append(NB_scores)\n",
    "Model_scores_list.append(DTC_scores)\n",
    "Model_scores_list.append(RFC_scores)\n",
    "\n",
    "for i in range(len(model_str)):\n",
    "\n",
    "    print(model_str[i] + \" Score : \" + str(mean(Model_scores_list[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d45bf0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
